# Copyright (c) Microsoft. All rights reserved.
# Licensed under the MIT license. See LICENSE file in the project root for full license information.



command=Train:Test
deviceId = 0
modelPath="./Test/seqcla.dnn"
makeMode = false # set true to enable checkpointing
traceLevel=1
vocabDim = 500000
outputPath="./Test/R"

Train=[
    action="train"
    
    BrainScriptNetworkBuilder=[
        # LSTM params
        lstmDim = 128
        cellDim = 128

        # model dims
        numLabels = 20
        vocabDim = $vocabDim$
        embedDim = 300
        OneWordLookahead (x) = Splice (x : DelayLayer {T=-1} (x): DelayLayer {T=-2} (x))
        BiRecurrentLSTMLayer {outDim} = {
            F = RecurrentLSTMLayer {outDim, goBackwards=false}
            G = RecurrentLSTMLayer {outDim, goBackwards=true}
            apply (x) = Splice (F(x):G(x))
        }.apply
        # define the model, by composing layer functions
        model = Sequential
        (
            EmbeddingLayer {embedDim} :  # load the pre-learned word embedding matrix
            OneWordLookahead:
            LinearLayer{lstmDim}:
            #
            RecurrentLSTMLayer {lstmDim} :
            BS.Sequences.Last :
            DenseLayer {numLabels, init="gaussian"}  # using "gaussian" for back compat/regresson tests only
        )

        # inputs
        t = DynamicAxis{}
        features = SparseInput {$vocabDim$, dynamicAxis=t}  # Input has shape (vocabDim,t) and is one-hot sparse
        labels   = Input {numLabels}                  # Input has shape (numLabels,*) where all sequences in *=1

        # apply model
        z = model (features)

        error2= Abs(Abs(z)-1)

        # Make sure the trainer understands that the time dimension of l3 is actually the same as that of labels.
        zp = ReconcileDynamicAxis(z, labels)

        # training criteria
        ce  = CrossEntropyWithSoftmax (labels, zp)  // this is the training objective
        err = ClassificationError     (labels, zp)  // this also gets tracked

        # connect to system
        featureNodes    = (features)
        labelNodes      = (labels)
        criterionNodes  = (error2:ce)
        evaluationNodes = (err)
        outputNodes     = (z)
    ]

    SGD = [	
        epochSize = 0
        minibatchSize = 1000
        maxEpochs = 1
        momentumPerMB = 0.9
        learningRatesPerMB = 0.1
    ]

    reader = [
        readerType = "CNTKTextFormatReader"
        file = "Sequence.txt"
		keepDataInMemory=true
		
        input = [
            features = [ alias = "x" ; dim = $vocabDim$ ; format = "sparse" ]
            labels =   [ alias = "y" ; dim = 20          ; format = "sparse" ]
        ]
   ]    
]

Test=[
    action="write"
    
    BrainScriptNetworkBuilder=[
        network=BS.Network.Load("$modelPath$")
        t = DynamicAxis{}
        outputNodes = (network.z)
    ]

    reader = [
        readerType = "CNTKTextFormatReader"
        file = "Sequence.txt"
        keepDataInMemory=true
        
        input = [
            features = [ alias = "x" ; dim = $vocabDim$ ; format = "sparse" ]
            labels =   [ alias = "y" ; dim = 20          ; format = "sparse" ]
        ]
   ]    
]

